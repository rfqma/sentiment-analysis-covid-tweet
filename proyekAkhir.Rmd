---
title: "Proyek Akhir Praktikum Data Science Plug E"
author: "Monica Elisabet (123200082) | Rifqi Maulana (123200128)"
date: "`r Sys.Date()`"
output: pdf_document
---
#Analisis Sentimen terhadap Tweet Masyarakat Indonesia yang mencakup Covid dan Pemerintah dengan Metode Naive Bayes


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Library
```{r}
library(vroom)
library(here)
library(sentimentr)
library(tidytext)
library(tidyr)
library(textclean)
library(tibble)
library(tm)
```

# Load Dataset
```{r}
rawData = read.csv("tweet-pemerintah-dan-covid.csv", header = T)
```

# Ubah Data (Tabel Kolom Tweet) Menjadi Vector
```{r}
tweets = rawData$tweet
tweets.text = Corpus(VectorSource(tweets))
```

# Cleaning Data
```{r}
removeURL <- function(x) gsub("http[^[:space:]]*", "",x)
clean <- tm_map(tweets.text, removeURL)

removeNL <- function(y) gsub("\n", " ", y)
clean <- tm_map(clean, removeNL)

removepipe <- function(z) gsub("<[^>]+>", "", z)
clean <- tm_map(clean, removepipe)

remove.mention <- function(z) gsub("@\\S+", "", z)
clean <- tm_map(clean, remove.mention)

remove.hashtag <- function(z) gsub("#\\S+", "", z)
clean <- tm_map(clean, remove.hashtag)

removeamp <- function(y) gsub("&amp;", "", y)
clean <- tm_map(clean, removeamp)

removetitik3 <- function(y) gsub("[[:punct:]]", "", y)
clean <- tm_map(clean, removetitik3)

remove.all <- function(xy) gsub("[^[:alpha:][:space:]]*", "", xy)
clean <- tm_map(clean,remove.all)

clean <- tm_map(clean, tolower)

## Menghilangkan Extra Whitespace (Spasi)
clean <- tm_map(clean, stripWhitespace)

## Load Stopword-ID
stopwordID <- "ID-stopwords.txt"

## Membaca Stopword-ID per-baris
cStopwordID <- readLines(stopwordID)

## Load Slangword (Bahasa Gaul)
slang <- read.csv("Slangword.csv", header = T)
old_slang <- as.character(slang$old)
new_slang <- as.character(slang$new)

## Load Stemming (Kata Imbuhan)
stemm <- read.csv("Stemming.csv", header = T)
old_stemm <- as.character(stemm$old)
new_stemm <- as.character(stemm$new)

## Load Lemmatization (Pengelompokan Infleksi Kata)
lemma <- read.csv("Lemmatization.csv", header = T)
old_lemma <- as.character(stemm$old)
new_lemma <- as.character(stemm$new)

stemmword <- function(x) Reduce(function(x,r) gsub(stemm$old[r],stemm$new[r],x,fixed=T),
                                seq_len(nrow(stemm)),x)
clean <- tm_map(clean,stemmword)
slangword <- function(x) Reduce(function(x,r) gsub(slang$old[r],slang$new[r],x,fixed=T),
                                seq_len(nrow(slang)),x)
clean <- tm_map(clean,slangword)
lemmatization <- function(x) Reduce(function(x,r) gsub(lemma$old[r],lemma$new[r],x,fixed=T),
                                    seq_len(nrow(lemma)),x)
clean <- tm_map(clean,lemmatization)

clean <- tm_map(clean, removeWords, cStopwordID)
writeLines(strwrap(clean[[2]]$content, 100))
```

# Save Data
```{r}
dataframe = data.frame(text = unlist(sapply(clean, `[`)), stringsAsFactors = F)
View(dataframe)
write.csv(dataframe, file = 'dataTweetBersih.csv')
```








# SENTIMENT ANALYSIS
# Library
```{r}
library(e1071)
library(caret)
library(syuzhet)
```

# Membaca File Data .csv yang sudah melewati proses Cleaning Data
```{r}
data <- read.csv("dataTweetBersih.csv", stringsAsFactors = FALSE)

## Deklarasi Variabel Kolom 'text' Menjadi Char
tweetss <- as.character(data$text)

## Memanggil Kamus Sentimen NRC untuk menghitung berbagai emosi dari isi kolom text
s <- get_nrc_sentiment(tweetss)

tweetss_combine <- cbind(data$text,s)
par(mar=rep(3,4))
a <- barplot(colSums(s), col = rainbow(10), ylab = 'count', main = 'Analisis Sentimen')
iki_ba <- a
```

# WORDCLOUD
# Library
```{r}
library(wordcloud)  # Library Wordcloud
library(tm)         # Library Penggunaan Corpus dalam Cleaning Data      
library(RTextTools) # Library Penggunaan Corpus dalam Cleaning Data
library(e1071)      # Library yang di dalamnya terdapat sebuah Algoritma Naive Bayes
library(dplyr)      # Library yang di dalamnya terdapat sebuah Algoritma Naive Bayes
library(caret)      # Library yang di dalamnya terdapat sebuah Algoritma Naive Bayes
```

# Akurasi
```{r}
require(corpus)

data.frame <- read.csv("dataLabelTweet.csv",stringsAsFactors = F)
data.frame$klasifikasi <- factor(data.frame$klasifikasi)
glimpse(data.frame)
set.seed(20)
data.frame<-data.frame[sample(nrow(data.frame)),]
data.frame<-data.frame[sample(nrow(data.frame)),]
glimpse(data.frame)
corpus<-Corpus(VectorSource(data.frame$text))
corpus
inspect(corpus[1:10])

#fungsinya untuk membersihkan data data yang tidak dibutuhkan 

corpus.clean<-corpus %>%
  tm_map(content_transformer(tolower)) %>% #digunakan untuk mengubah huruf besar dari string menjadi string huruf kecil
  tm_map(removePunctuation)%>% #menghapus tanda baca
  tm_map(removeNumbers)%>% #menghapus nomor
  tm_map(removeWords,stopwords(kind="en"))%>% #menghapus stopwords
  tm_map(stripWhitespace) 
dtm<-DocumentTermMatrix(corpus.clean)
inspect(dtm[1:10,1:20])

df.train<-data.frame[1:340,]
df.test<-data.frame[341:680,]   

dtm.train<-dtm[1:340,]
dtm.test<-dtm[341:680,]

corpus.clean.train<-corpus.clean[1:340]
corpus.clean.test<-corpus.clean[341:680]

dim(dtm.train)

fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)

dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))
dim(dtm.train.nb)

dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))
dim(dtm.test.nb)

#Boolan Naive Bayes
convert_count <- function(x){
    y<-ifelse(x>0,1,0)
    y<-factor(y,levels=c(0,1),labels=c("no","yes"))
    y
}

#Naive Bayes Model
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,2,convert_count)
#Training
classifier <- naiveBayes(trainNB, df.train$klasifikasi, laplace = 1)

#Use the NB classifier we built to make predictions on the test set
pred <- predict(classifier, testNB)

#Create a truth table by tabulating the predicted class labels with the actual predicted class labels with the actual class labels
NB_table=table("Prediction"= pred, "Actual" = df.test$klasifikasi)
NB_table

#confussion Matrix
conf.matNB <- confusionMatrix(pred, df.test$klasifikasi)
conf.matNB

```

# Generate Wordcloud untuk kata-kata yang sering muncul dari dataset tweet masyarakat indonesia yang telah dibersihkan
```{r}
wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))
```

# Skoring
```{r}
kalimat2 <- read.csv("dataTweetBersih.csv", header=TRUE)
kata.positif <- scan("positivewords.txt", what="character", comment.char=";")
kata.negatif <- scan("negativewords.txt", what="character", comment.char=";")
score.sentiment = function(kalimat2, kata.positif, kata.negatif, .progress='none')
{
  require(plyr)
  require(stringr)
  scores = laply(kalimat2, function(kalimat, kata.positif, kata.negatif) {
    kalimat = gsub('[[:punct:]]', '', kalimat)
    kalimat = gsub('[[:cntrl:]]', '', kalimat)
    kalimat = gsub('\\d+', '', kalimat)
    kalimat = tolower(kalimat)
    list.kata = str_split(kalimat, '\\s+')
    kata2 = unlist(list.kata)
    positif.matches = match(kata2, kata.positif)
    negatif.matches = match(kata2, kata.negatif)
    positif.matches = !is.na(positif.matches)
    negatif.matches = !is.na(negatif.matches)
    score = sum(positif.matches) - (sum(negatif.matches))
    return(score)
  }, kata.positif, kata.negatif, .progress=.progress)
  scores.df = data.frame(score=scores, text=kalimat2)
  return(scores.df)
}
hasil = score.sentiment(kalimat2$text, kata.positif, kata.negatif)
# Mengubah nilai score menjadi sentimen
hasil$klasifikasi <- ifelse(hasil$score < 0, "Negatif", ifelse(hasil$score==0, "Netral", "Positif"))
hasil$klasifikasi
# Menukar Urutan Baris
data <- hasil[c(3,1,2)]
# View Data
write.csv(data, file = "dataLabelTweet.csv")
```

# SHINY (Membuat Tampilan)
# Library
```{r}
library(shiny)
```

# Script UI
```{r}
dataLabel <- read.csv("dataLabelTweet.csv")

ui <- fluidPage(
  
  ## Judul Aplikasi
  titlePanel("Analisis Sentimen Terhadap Tweet Masyarakat Indonesia Tentang Covid dan Pemerintah"),
  mainPanel(
    ##textOutput("selected_var"),
    
    ##plotOutput("asPlot"),
    tabsetPanel(type = "tabs",
                tabPanel("Data Asli", DT::dataTableOutput('tbl')),
                tabPanel("Data Bersih", DT::dataTableOutput('tbl2')),
                tabPanel("Skoring", DT::dataTableOutput('tbl3')),
                tabPanel("Scatterplot", plotOutput("asPlot")),
                tabPanel("Wordcloud", plotOutput("wordcl"))
    )
  )
)
```

# Script Server
```{r}
## Membuat fungsi input, output, session
## Di dalam fungsi ini berisi kode pemrosesan data untuk ditampilkan di dalam beberapa tab shiny
## Membuat input dan menampilkan hasil pada output
server <- function(input, output, session) {
  as_data <- reactive({
    
    input$Update
    isolate({
      withProgress({
        setProgress(message = "Processing analisis...")
        as_file <- input$as
        if(!is.null(as_file)){
          as_text <- readLines(as_file$datapath)
        }
        else
        {
          as_text <- "A Barplot is an immage made of words that..."
        }
        
      })
    })
  })
  
  barplot_rep <- repeatable(barplot)
  
  # Menampilkan data asli
  output$tbl = DT::renderDataTable({
    DT::datatable(rawData, options = list(lengthchange = FALSE))
  })
  # Menampilkan Data Bersih
  output$tbl2 = DT::renderDataTable({
    DT::datatable(data, options = list(lengthchange = FALSE))
  })
  # Menampilkan Skoring
  output$tbl3 = DT::renderDataTable({
    DT::datatable(dataLabel, options = list(lengthchange = FALSE))
  })
  # Menampilkan Grafik Analisis Sentimen
  output$asPlot <- renderPlot({ withProgress({
    setProgress(message = "Creating barplot...")
    barplot(colSums(s),col = rainbow(10),ylab = 'count',main = 'Sentiment Analysis')
  })
  })
  # Menampilkan Wordcloud
  output$wordcl <- renderPlot({
    wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))
  })
  
}
```

# Running Shiny
```{r}
shinyApp(ui = ui, server = server, options = list(height = "600px"))
```

